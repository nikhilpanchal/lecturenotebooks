{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test Driven Development (TDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Test Driven Development, relates to writing code as per specifications set by tests. The process involvles capturing user requirements, or system behaviour in small incremental tests, and then writing code to get those tests to pass. This typically results in building systems incrementally with small blocks of code and then building additional behavior that sits on top of previously built code, taking one test at a time and getting it to pass.\n",
    "\n",
    "The process follows three main steps that are then repeated over and over again.\n",
    "\n",
    " - Red\n",
    "  - Write a test before the code (causing it to fail). The missing code causes the test to go `Red`.\n",
    " - Green\n",
    "  - Write the code to get the test to pass using the `Quickest path to Green` method.\n",
    " - Refactor\n",
    "  - Refactor the code to better structure it whilst keeping the tests green. The Green tests ensure you are starting this test with working code.\n",
    "\n",
    "Repeat with the next required behaviour.\n",
    "\n",
    "### Advantages\n",
    " - Incremental build of the system allows its architecture to `evolve` as per the systems need.\n",
    "  - As opposed to deciding an architecture up front which would most likely not capture all cases.\n",
    "  - Results in a system that is more amenable to change.\n",
    " - Results in (close to) 100% test coverage, ensuring well tested code that inspires developer and user confidence\n",
    " - The tests ensure new features can be added or existing code can be modified without breaking functionality\n",
    " - Bugs or logic breaks are caught and fixed early in development process\n",
    "  - Any code change that breaks existing logic will create red tests, leading to early bug detection and fixes\n",
    " - Results in the testing cycle being almost entirely automated with tests run dozens of times a day or on every build\n",
    "  - *Important to keep tests small and their executions quick*\n",
    "  \n",
    "### Concerns\n",
    " - Can *appear* to take longer time due to `double` work\n",
    " - Counter-intuitive: Not natural to first timers to write a test before writing the real code\n",
    " - Can result in `brittle` tests: Any small change in the code result in the refactoring of the tests as well.\n",
    "  - Usually occurs if the tests are written after the code\n",
    "  - *This is why tests should check for `behaviour` not code*.\n",
    " - Different languages provide differing levels of support\n",
    " \n",
    "In the real world BDD is implemented in various differing flavors. Teams often write the tests after writing code to have tests serve as safeguards against logic-breaking code modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tests\n",
    "\n",
    "Tests are separate bits of code in addition to the main application code that are written to confirm and verify the desired behavior of various scopes of application. These are the responsibility of the `developer` and are typically written as the main application is being written. Each of these tests are **self contained**, in that each test is responsible for setting up the system before running the actual test and tearing it down after the test is run. \n",
    "\n",
    "Application tests can be grouped into three main categories, that differ in terms of the scope of the application code that they are written to verify (cover). These are\n",
    "\n",
    " 1. Unit Tests\n",
    " 1. Integration Tests\n",
    " 1. End-to-End (Feature) Tests\n",
    " \n",
    "### Unit Tests\n",
    "\n",
    " - A Unit test has the smallest scope or code coverate of testing where each unit tests checks a small `unit` of code in isolation. \n",
    " - If the unit has any interaction with another dependent unit or module that dependency is `mocked` out.\n",
    " - Is the most fine-grained of all tests, requiring a lot of unit tests to cover the entire codebase.\n",
    " - Each test must execute as quickly as possible in order to lend itself to automation.\n",
    " \n",
    "### Integration Tests\n",
    " \n",
    " - Tests that two or more units or modules work together (integrate) as expected.\n",
    "  - eg. Test that checks for the interaction between server code and a database.\n",
    " - Can take longer to run than unit-tests due to remote calls and other integrations that need to run as part of the test\n",
    " - Requires more setup than unit tests (like setting up a fake server or test database to integrate with)\n",
    " \n",
    "### End-to-End Tests\n",
    "\n",
    " - Also called `Feature Tests`, they test out a high level feature of the application\n",
    "  - Tests the application at the highest level of abstraction, mostly oblivious to the way the app is implemented\n",
    " - These involve testing an application at the browser level, simulating real user interaction with the system\n",
    " - Take the longest to run, most expensive to write and most prone to failure\n",
    "  - Involves communication between the client (browser) and server layers which will take the same time as a real feature execution\n",
    "  - Run using tools like Selenium that has its own learning curve\n",
    "  - Most prone to failure when changes are made to the system, increasing maintenance cost\n",
    "  - Less deterministic than unit or integration tests\n",
    " \n",
    " \n",
    "### Testing Pyramid\n",
    "The rule of thumb for a typical application is to have the largest number of fine-grained unit tests, a smaller number of integration tests and then an even smaller set of end to end tests.\n",
    "\n",
    "![Testing Pyramid](https://2.bp.blogspot.com/-YTzv_O4TnkA/VTgexlumP1I/AAAAAAAAAJ8/57-rnwyvP6g/s1600/image02.png \"Testing Pyramid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tests in Python\n",
    "\n",
    "Testing support in python is mainly provided by the `unittest` module. This provides support for test automation, sharing of test setup and teardown across individual test cases, Grouping of related tests as `Suites` of tests and finally, a report generation framework to print out the results of the test run.\n",
    "\n",
    "`unittest` as the name suggests, is mainly used to write **unit tests**, however they can be used to write **integration tests** as well.\n",
    "\n",
    "### Basic Components\n",
    "\n",
    "In order to write tests for the `unittest` module to run, you would need to provide the following main components in order to be compliant with unittest's automation test runner.\n",
    "\n",
    "#### TestCase\n",
    "A class that encompasses a set of related tests. This class would need to be a `subclass` of the module provided `unittest.TestCase` class.\n",
    "\n",
    "```python\n",
    "import unittest\n",
    "class MyTests(unittest.TestCase):\n",
    "\n",
    "```\n",
    "\n",
    "#### Individual Tests\n",
    "Each individual test is written as an instance function in the TestCase class. In order for these methods to be triggered by the test runner, their names must be of the form **test_***\n",
    "\n",
    "```python\n",
    "class MyTests(unittest.TestCase):\n",
    "    def test_myunit_test(self):\n",
    "        # assertions\n",
    "        \n",
    "```\n",
    "\n",
    "#### Assertion statements\n",
    "The assertion statements are found within each test and is how the expected behavior of the functionality under test is checked. The `unittest.TestCase` class provides a large set of instance `assert*` functions that you can call to make various types of assertions.\n",
    "\n",
    "```python\n",
    "class MyTestCase(unittest.TestCase):\n",
    "    def test_myunit_test(self):\n",
    "        self.assertEqual(1, 1, \"Expected the output to be 1\")\n",
    "```\n",
    "\n",
    "A list of the more commonly used assert statements can be found [here](https://docs.python.org/3.5/library/unittest.html#assert-methods)\n",
    "\n",
    "#### setUp and tearDown\n",
    "Helper methods of the `unittest.TestCase` class that can be overridden to provide setUp and teardown for each test. The setup method is run before the execution of each test and the teardown is run immediately after each test is run. The setup method can also be used to create any kind of shared data used by the tests. This ensures that the TestCase class is `DRY` so that code that is commonly required by all `test_*` methods is written once and re-used.\n",
    "\n",
    "These methods are what makes the `TestCase` class self-contained. Each run of the `TestCase` class must manage its own setup required for the tests to run, and once completed must also be responsible for any clean-up operations required to leave the system in a good state.\n",
    "\n",
    "```python\n",
    "class MyTestCase(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.dep_system = DepSystem()\n",
    "        self.shared_data = list([0, 1, 2, 3])\n",
    "        \n",
    "    def tearDown(self):\n",
    "        self.dep_system.shutDown()\n",
    "```\n",
    "\n",
    "#### TestSuite\n",
    "`unittest.TestSuite` is a class provided to create groups or `suites` of TestCases. \n",
    "\n",
    "```python\n",
    "def suite():\n",
    "    suite = unittest.TestSuite()\n",
    "    suite.addTest(MyTestCase('test_myunit_test'))\n",
    "    suite.addTest(MyOtherTestCase('test_myother_test'))\n",
    "    return suite\n",
    "```\n",
    "\n",
    "The `unittest` Test runner provides default grouping for tests in each TestCase class for you so unless you want custom grouping into suites, this is less frequently used.\n",
    "\n",
    "#### Decorators\n",
    "There are several test method decorators that you can use to determine the set of tests that you want to run\n",
    "\n",
    " 1. **@unittest.skip** \n",
    "Decorating a `test_*` method with `@unittest.skip` will cause the test runner to skip this test. This test will be marked as skipped in the test run report\n",
    "\n",
    " 1. **@unittest.skipif**\n",
    "Conditionally skip a test\n",
    "\n",
    " 1. **@unittest.expectedFailure**\n",
    "If you know a test is set to fail, you can use this decorator to prevent it messing up your test report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Example\n",
    "\n",
    "Consider the following example class that tests out the functionality of the String operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...s.\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.004s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import datetime\n",
    "\n",
    "class StringTests(unittest.TestCase):\n",
    "    \"\"\"Unit testing class for Strings\"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "        self.str = \"TestString\"\n",
    "\n",
    "    def test_concat_strings(self):\n",
    "        stra = \"Word\"\n",
    "\n",
    "        self.assertEqual(self.str + stra, \"TestStringWord\", \"It should concatenate strings\")\n",
    "\n",
    "    def test_lower(self):\n",
    "        self.assertEqual(self.str.lower(), \"teststring\", \"It should convert all characters to lower case\")\n",
    "        \n",
    "    def test_format(self):\n",
    "        result = \"Format check {}\".format(2)\n",
    "        self.assertEqual(result, \"Format check 2\", \"formatting not done correctly\")\n",
    "        \n",
    "    def test_isdigit(self):\n",
    "        # Check that it throws an exception\n",
    "        with self.assertRaises(TypeError):\n",
    "            self.str.split(2)\n",
    "        \n",
    "    @unittest.skipIf(datetime.date.today().month > 2, \"Can't run this test after Feb\")    \n",
    "    def test_length(self):\n",
    "        result = len(self.str)\n",
    "        self.assertEqual(result, 10, \"String is of length 10\")\n",
    "\n",
    "    def tearDown(self):\n",
    "        pass\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    # Arguments to main added due to iPython. You'd run this as unittest.main()\n",
    "    unittest.main(argv=[\"Ignored\"], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "TestCases must be entirely self-contained units of code that handle all of the setup and teardown that the individual test assertions require. They should **NOT** rely on any kind of manual intervention. This makes them scriptable and \"automatable\" (TestCases will typically be run as part of an automated build script).\n",
    "\n",
    "Additionally, the tests should produce minimal output about its inner details. The only output from the tests should be whether the tests all passed and if not which ones failed and why. For failures, it may provide stacktraces to provide points of further investigation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Write a simple class called `ArithmeticCalculator` that exposes functions that perform the simple arithmetic operations of `add`, `subtract`, `multiply` and `divide`. Then write a `TestCase` that contains unit tests that test out the functionality of the exposed functions.\n",
    "\n",
    "#### Directory Structure\n",
    "All tests should be written inside a `tests` folder that will be in your `src` folder. The directory structure of the tests folder should mirror that of the src folder.\n",
    "\n",
    "#### Execution Instructions\n",
    "You should unittests Test runner to execute your tests\n",
    "\n",
    " 1. Using the unittest test runner on the command line\n",
    " This will run all of the tests that are in the file `<filename>.py`.\n",
    " ```bash\n",
    " python -m unittest tests/<filename>.py\n",
    " ```\n",
    " \n",
    " 1. Using the discover mechanism\n",
    " This will look for all files under the tests directory with the filename that matches the pattern `*.py` and run them\n",
    " ```bash\n",
    " python -m unittest discover -s tests -p *.py\n",
    " ```\n",
    " \n",
    " 1. Triggering the test runner from within your code\n",
    " ```python\n",
    " if __name__ == \"__main__\":\n",
    "     unittest.main()\n",
    " ```\n",
    " \n",
    "There are several command line options that you can provide to the unittest Test Runner which are described [here](https://docs.python.org/3.5/library/unittest.html#command-line-options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
